# MODULE 19 Challenge 
# CryptoClustering - Unsupervised Learning Challenge
## Patricia Daher
Using Python and unsupervised learning to predict if cryptocurrencies are affected by 24-hour or 7-day price changes.

## Overview
This project applies unsupervised machine learning (K-Means clustering) and Principal Component Analysis (PCA) to analyze cryptocurrency market data. The goal is to group cryptocurrencies based on their 24-hour and 7-day price changes and compare clustering results before and after dimensionality reduction.

## Repository Structure
CryptoClustering/  
├── Crypto_Clustering.ipynb          # Jupyter Notebook with the analysis  
├── Resources/  
│   └── crypto_market_data.csv       # Dataset used for clustering  
├── README.md                        # Project documentation  
└── LICENSE                      # Specifies files to ignore in Git  

## Project Steps

### Data Preparation
Load and explore the dataset (crypto_market_data.csv).
Normalize the data using StandardScaler().
Set coin_id as the index.

2. Finding Optimal K (Elbow Method)
Apply the elbow method on the scaled data to determine the best number of clusters (k).
Plot the inertia values for k = 1 to 11.

3. K-Means Clustering (Original Data)
Train a K-Means model with the optimal k.
Predict clusters and visualize results with hvPlot.

4. Dimensionality Reduction (PCA)
Apply PCA to reduce features to 3 principal components.
Calculate the total explained variance.
Create a new DataFrame with the PCA-transformed data.

5. K-Means Clustering (PCA Data)
Repeat the elbow method on the PCA data to find the new optimal k.
Compare results with the original clustering.
Visualize clusters using PC1 and PC2.

6. Comparative Analysis
Create composite plots to compare:
Elbow curves (original vs. PCA data).
Clustering results (original vs. PCA data).
Answer: How does reducing features impact clustering?

### Requirements
1- Data Preparation
Normalize data using StandardScaler().
Maintain coin_id as the index.

2- Optimal K (Elbow Method)
Compute inertia for k = 1 to 11.
Plot and determine the best k.

3- K-Means Clustering
Fit and predict clusters.
Visualize with hvPlot (original and PCA data).

4- PCA Analysis
Reduce features to 3 principal components.
Calculate explained variance.

5- Comparative Visualization
Overlay elbow curves and clustering results.
Analyze the impact of PCA on clustering.

6- Key Questions Answered
What is the best k value for the original data?
What is the total explained variance of the three principal components?
Does PCA change the optimal k?
How does reducing features affect clustering results?

### Technology Used
Python 3.7+
Jupyter Notebook
pandas
scikit-learn
hvPlot

### References:
Data Source: Generated by edX Boot Camps LLC (educational use only).